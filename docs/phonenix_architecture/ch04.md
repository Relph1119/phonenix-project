# 第四部分 不可变基础设施

## 1 虚拟化容器

### 1.1 虚拟化技术

- 指令级虚拟化：软件模拟不同ISA架构的处理器工作过程，典型代表：QEMU、Bochs
- 硬件抽象层虚拟化：以软硬件模拟处理器、芯片组、内存、磁盘控制器、显卡等设备的工作过程，典型代表：VMware ESXi、Hyper-V
- 操作系统层虚拟化：容器化
- 运行库层虚拟化：使用软件翻译方法模拟系统，典型代表：WINE、WSL
- 语言层虚拟化：有虚拟机间高级语言生成的中间代码转换为目标机器的可执行指令，典型代表：JVM（Java）、CLR（.Net）

### 1.2 容器技术演变

- 隔离文件：chroot，提供进程与子进程的访问目录/文件的隔离机制
- 隔离访问：名称空间，内核针对进程设计的访问隔离机制
- 隔离资源：cgroup，控制群组子系统，隔离或分配并限制进程组能够使用的资源配额
- 封装系统：LXC，Linux容器的系统级虚拟化
- 封装应用：Docker，提供跨机器的绿色部署、以应用为中心的封装、自动构建、多版本支持、组件重用、共享、工具生态
- 封装集群：Kubernetes，容器编排框架，从传统IDC（网络数据中心）到建立CNCF（云原生基金会）

### 1.3 以容器构建系统

1. 隔离与协作
   - 超亲密协作的默认共享内容
     - UTS名称空间：相同主机名和域名
     - 网络名称空间：共享一样的网卡、网络栈和IP地址
     - IPC名称空间：通过信号量或POSIX共享内存
     - 时间名称空间：共享相同的系统时间

   - 普通非亲密协作：采用网络交互方式

2. 韧性与弹性
   - 控制回路：监视资源的控制器驱动资源的实际状态逐渐向期望状态靠拢（声明式API）
   - 自动恢复：使用ReplicSet的回收机制
   - 滚动更新：控制Deployment的更新
   - 自动扩缩：Autoscaling资源和自动扩缩控制器，自动根据度量指标设置Deployment的期望状态

### 1.4 以应用为中心的封装

- Kustomize：根据环境生成不同的部署配置，分离开发和运维工作
- Helm：使用Chart格式的Repository应用仓库，部署应用时，先间管理员设置的值覆盖到values.yaml默认值上，以字符串替换传递给templates目录的资源模板，生成要部署到k8s的资源文件
- Operator：使用自定义资源（CRD），管理应用及其组件的自定义k8s控制器
- 应用状态
  - 无状态的应用：持有运行所需的数据，每次运行都和首次运行一样
  - 有状态的应用：用户能察觉到该应用已经发生变化

- StatefulSet管理的Pod特性：会按顺序创建和销毁、具有稳定的网络名称、具有稳定的持久化存储

### 1.5 开放应用模型（OAM）
        
- Component（服务组件）：抽象那些应由开发人员关注的元素（应用的名字、容器镜像、运行所需的参数）
- Workload（工作负荷）：决定应用的运行模式，共6个模式，包括Server、Singleton Server、Worker、Singleton Worker、Task、Singleton Task
- Trait（运维特征）：用于封装模块化后的运维能力，设置运维中的可重复操作（日志收集、负载均衡、水平扩缩容）
- Application Scope（应用边界）：按照Component特性或作用域划分Scope
- Application Configuration（应用配置）：将Component（必需）、Trait（必需）、Scope（非必需）组合到一起进行实例化，形成完整的应用配置

## 2 容器间网络
    
### 2.1 Linux网络虚拟化

1. 网络通信模型：逐层调用、逐层封装
   
2. 干预网络通信：基于Netfilter框架
    - 提供钩子干预
        - PREROUTING：进入IP路由之前触发，用于目标网络地址转换（DNAT）
        - INPUT：报文经过IP路由后，如果确定发往本机时触发，用于加工发往本地进程的数据包 
        - FPRWARD：报文经过IP路由后，如果确定不是发往本机时触发，用于处理转发到其他及其的数据包
        - OUTPUT：从本机程序发出的数据包，经过IP路由前触发，用于加工本地进程的输出数据包
        - POSTROUTING：监听本机网卡发出的数据包，用于源网络地址转换（SNAT）
    - iptable的规则表
        - raw表：用于取出数据包上的连接追踪机制
        - mangle表：用于修改书包的报文头信息，典型应用：链路的服务质量管理QoS
        - nat表：用于修改书包的源或者目的地址等信息，典型应用：网络地址转换
        - filter表：用于对数据包进行过滤，典型应用：防火墙
        - security表：用于在数据包上应用SELinux

3. 虚拟化网络设备
    - 网卡：tun/tap、veth
        - tap模拟以太网设备，操作二层数据包（以太帧）
        - tun模拟网络层设备，操作三层数据包（IP报文）
        - veth虚拟以太网，用于两个独立网络名称空间中

    - 交换机：Linux Bridge
        - 支持二层转发、泛洪、MAC学习、地址转发表、STP
        - 支持把发给它自身的数据包接入主机的三层协议栈中

    - 网络：VXLAN
        - 软件定义网络（SDN）：在物理网络上构造一层虚拟化网络，将控制平面和数据平面分离，实现流量的灵活控制
        - 解决VLAN两个缺陷：VLAN Tag的设计（32位存储空间太小）、跨数据中心传递

    - 副本网卡：MACVLAN
        - 借用VLAN子接口的思路，允许同一个网卡设置多个IP地址
        - 在物理设备之上、网络栈之下生成多个虚拟设备

4. 容器间通信
    - 桥接模式：为新容器分配独立的网络名称空间，接入docker0网桥
    - 主机模式：无须进行NAT转换，容器直接使用宿主机的真实设施
    - 空置模式：容器只有一个回环设备，便于用户自定义玩如果配置
    - 容器模式：新容器加入指定的容器网络名称空间，共享网络资源
    - MACVLAN模式：指定副本网卡的MAC地址使用宿主机的物理设备
    - Overlay模式（很少使用）：使用VXLAN网络

### 2.2 容器网络与生态
- CNM与CNI（容器网络接口）：管理网络创建与删除、管理IP地址分配与回收
- 网络插件生态
    - Overlay模式：Flannel（VXLAN模式）、Calico（IPIP模式）、Weave，不受底层物理网络接口的约束，但额外的包头封装导致信息密度降低
    - 路由模式：直接通过路由转发实现跨主机通信，依赖底层网络环境的支持
    - Underlay模式：最大限度地利用硬件能力，容器的网络接口能够直接与底层网络通信

## 3 持久化存储

### 3.1 Kubernetes存储设计演变

1. Mount
    - Bind：用于把宿主机的目录挂载到容器的指定目录下
    - Volume：提升Docker对不同存储介质的支撑能力，抽象存储资源
    - tmpfs：用于内存中读写临时数据

2. 静态存储分配
    - 持久化PersistentVolume：独立于Pod存在，不依附任何宿主机节点
    - PersistentVolume的匹配过程
        - （1）管理员准备好使用的存储系统，具备跨主机共享的能力
        - （2）管理员手工预先分配若干个PersistentVolume，定义每个PersistentVolume提供的具体能力
        - （3）用户根据业务创建PersistentVolumeClaim，声明Pod运行所需的存储能力
        - （4）匹配PersistentVolume和PersistentVolumeClaim，建立绑定关系
        - （5）继续Pod的创建过程


3. 动态存储分配（StorageClass的资源分配过程）
    - （1）管理员准备好资源分配器，可使用默认的In-Tree资源分配器
    - （2）配置StorageClass（满足存储需求）
    - （3）用户根据业务创建PersistentVolumeClaim（描述存储需求），声明Pod的所需存储，并指定StorageClass
    - （4）检查PersistentVolumeClaim的StorageClass及资源分配器是否可用，自动生成满足的PersistentVolume
    - （5）资源分配器收到了创建请求后，操作存储系统分配空间
    - （6）继续Pod的创建过程

### 3.2 容器存储与生态
1. Kubernetes存储架构
    - PV控制器：跟踪“所有未绑定的PersistentVolume都能处于可用状态”和“所有处于等待状态的PersistentVolumeClaim都能匹配到与之绑定的PersistentVolume”，并执行Provision/Delete操作
    - AD控制器：跟踪“所有被调度到的准备创建新Pod的节点都附加了要使用的存储设备”，并执行Attach/Detach操作
    - Volume管理器：用于支持本节点中Vloume执行Attach、Detach、Mount、Unmount操作

2. FlexVolume的缺陷
    - 并不是全功能的驱动，不包含Provision和Delete操作
    - 部署、维护都相对繁琐
    - 实现复杂交互时相对繁琐

3. CSI：存储扩展规范，包括整体架构、Volume的生命周期模型、驱动注册、Volume创建、挂载、扩容、快照和度量等

4. 存储类型
    - 块存储：读写访问数据需要使用与存储类型相匹配的协议，性能最优，吞吐量高，延迟低
    - 文件存储：使用链表结构，形成文件分配表（FAT）
    - 对象存储：以非结构化数据为目标的存储方案，将一大批对象的元数据集中存放，用多台OSD服务器存储对象的数据块部分，适合CDN一类的应用

## 4 资源与调度

### 4.1 资源模型

- Node：资源的提供者
    - 按照类型，可分为计算资源、存储资源和网络资源
    - 按照资源压缩，可分为可压缩资源（如CPU）、不可压缩资源（如内存）

- Pod：资源的使用者

### 4.2 服务质量与优先级

- k8s的资源分配设计：requests（供调度器使用），limits（供cgroups使用）
- 服务质量等级
    - Guaranteed：一些重要的必须不能中断的业务
    - Burstable
    - BestEffort：一些临时的，不那么重要的任务

- Pod优先级：通过PriorityClass的资源实现
- 资源抢占原则：根据优先级低于待调度的Pod的所有已调度的Pod里，按照优先级从低到高排序，从最低的杀Pod，直至腾出的资源足以支持待调度Pod成功调度所需的资源为止，或者已经找不到更低优先级的Pod为止

### 4.3 驱逐机制

- 软驱逐：配置一个较低的警戒线，减少资源抖动对服务的影响
- 硬驱逐：配置一个较高的终止线，保障核心系统的稳定
- 优雅退出期

### 4.4 默认调度器

- Predicate筛选算法：从集群中找到一批剩余资源可以满足Pod运行
    - 通用过滤策略：检查节点是否满足Pod的资源需求
    - 卷过滤策略：检查节点挂载的Volume是否存在冲突
    - 节点过滤策略：污点与容忍度

- Priority评价算法：从符合运行要求的节点中找出一个最合适的节点完成调度
    - LeastRequestedPriority规则：选择处理器和内存空闲资源最多的节点
    - BlancedResourceAllocation规则：希望完成调度后，所有节点里各种资源的分配尽量均衡

## 5 服务网格

### 5.1 服务网格的演变

1. 通信成本的演变
    - 第1阶段：将通信的非功能性需求视作业务需求的一部分，通信的可靠性由开发人员来保障
    - 第2阶段：将代码中的通信功能抽离重构成公共组件库，通信的可靠性由专业的平台开发人员来保障
    - 第3阶段：将负责通信的公共组件库分离到进程之外，程序间通过网络代理来交互，通信的可靠性由专门的网络代理提供商来保障
    - 第4阶段：将网络代理以边车的形式注入应用容器，自动劫持应用的网络流量，通信的可靠性由专门的通信基础设施来保障
    - 第5阶段：将边车代理统一管控起来，实现安全、可控、可观测的通信，将数据平面与控制平面分离开来，实现通用、透明的通信，由专门的服务网络框架来保障

2. 数据平面
    - 代理注入
        - 基座模式：提供SDK处理通信
        - 注入模式
            - 手动注入模式：通过命令给Pod增加一个额外容器
            - 自动注入模式：依靠动态准入控制中的Mutating Webhook控制器实现

    - 流量劫持
        - 传统方式：基于iptables进行数据转发
        - 优化方案：eBPF技术，在Socket层面直接完成数据转发

    - 可靠通信
        - 代理转发行为规则
            - Listener：用于接收来自下游应用程序的数据，使用LDS服务自动发现Listener
            - Router（服务网关）：决定Listener在接收到下游的数据之后，选择数据处理的Cluster，提供目标Cluster及其匹配规则
            - Cluster（服务发现）：提供相同服务的上游主机，包括服务连接池、超时时间、Endpoint地址、端口、类型等信息

3. 控制平面
    - 数据平面交互：边车注入、策略分发、配置分发
    - 流量控制：请求路由、流量治理、调试能力
    - 通信安全：生成CA证书、SDS服务代理、认证、授权
    - 可观测性
        - 日志收集：使用ELK Stack完成
        - 链路追踪：通过Zipkin等追踪系统从数据中重建服务调用链
        - 指标度量：基于4类监控标识（响应延迟、流量大小、错误数量、饱和度）生成一系列观测不同服务的监控指标

### 5.2 服务网格与生态

- 服务网络接口（SMI）
    - 流量规范：定义流量的表示方式
    - 流量拆分：定义不同版本服务之间的流量比例
    - 流量度量：为资源提供通用集成点
    - 流量访问控制：根据客户端身份配置，对特定的流量访问特定的服务，并提供简单的访问控制

- 通用数据平面API（UDPA）
- 服务网络生态
    - 数据平面产品：Linkerd（需要Java虚拟机支持）、Envoy（C++）、nginMesh（C）、Conduit/Linkerd 2（Rust）、MOSN（Golang） 
    - 控制平面产品：Linkerd 2、Istio（目前功能最强大）、Consul Connect（整合集成的角色定位）、OSM（微软）
